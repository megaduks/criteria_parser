# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_core.ipynb.

# %% auto 0
__all__ = ['load_eligibility_criteria', 'extract_entities', 'entity_coverage']

# %% ../nbs/00_core.ipynb 3
import pandas as pd
import numpy as np

from pathlib import Path
from typing import List

# %% ../nbs/00_core.ipynb 5
def load_eligibility_criteria() -> pd.DataFrame:
    
    _lst = []
    
    ent_map = {
        "drugs": "Drug", 
        "persons": "Person", 
        "procedures": "Proceure", 
        "conditions": "Condition",
        "devices": "Device",
        "visits": "Visit",
        "scopes": "Scope",
        "observations": "Observation",
        "measurements": "Measurement",
    }
    
    for mode in ["_inc", "_exc"]:
        
        criteria_files = Path("data").glob(f"*{mode}.txt")

        for f in criteria_files:
            clinical_trial_no = str(f).lstrip("data/").rstrip(f"{mode}.txt")

            with open(f, "rt") as f:
                criteria = " ".join(f.read().splitlines())
                
            _rec = {}

            _rec["ct_no"] = clinical_trial_no
            _rec["criteria"] = criteria
            _rec["mode"] = "inclusion" if mode == "_inc" else "exclusion"

            for e in ent_map:
                ents = extract_entities(clinical_trial_no, mode, ent_map[e])
                _rec[e] = ents if ents else None

            _lst.append(_rec)
        
    return pd.DataFrame(_lst)

# %% ../nbs/00_core.ipynb 6
def extract_entities(ct: str, mode: str, e: str) -> List:
    entities = []
    
    with open(f"data/{ct}{mode}.ann", "rt") as f:
        data = f.read().splitlines()
        
    for row in data:
        if e in row:
            entities.append(" ".join(row.split()[4:]))

    return entities

# %% ../nbs/00_core.ipynb 8
from typing import List, Tuple

def entity_coverage(ents_true: List[str], ents_pred: List[str], symmetric: bool=True) -> Tuple[float, float]:
    """Compute the compound metric of entity coverage in eligibility criteria
    
    Args:
        ents_true: list of entities from Chia annotations
        ents_pred: list of entities returned from LM
        symmetric: if True, the Jaccard denominator is the union of sets of entities, otherwise
        only true entities are counted in the denominator
        
    For each entity in a criterion, find the predicted entity which maximizes the Jaccard score and
    return the average Jaccard score for matched entities and the percentage of entites for which
    any matching has been found
    """

    def _jaccard(a, b):
        if (not a or not b):
            return 0.0
    
        return len(set(a).intersection(set(b))) / (len(set(a).union(set(b))) if symmetric else len(set(a)))
    
    ents_true = [] if not ents_true else ents_true # make sure that ents_true is iterable
    
    if not ents_pred:
        return (0., 0.) # max() cannot operate on empty sequence

    scores = [
        max([_jaccard(e_true.split(), e_pred.split()) for e_pred in ents_pred])
        for e_true
        in ents_true
    ]
    non_zero_scores = [s for s in scores if s > 0]
    
    if not non_zero_scores:
        return (0., 0.)
        
    return (
        sum(non_zero_scores) / len(non_zero_scores), # average Jaccard score of matched entities
        len(non_zero_scores) / len(scores), # percentage of matched entities
    )
        
